{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37656ab3-ba6f-45b5-8af7-454225225dcd",
   "metadata": {},
   "source": [
    "# Evaluating different architecture for our Gunshot detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebcd0b-e8c8-4a6a-88b9-950c4b961069",
   "metadata": {},
   "source": [
    "We recall from our preprocessing method comparison that using mel spectrograms is the most powerful preprocessing technique one can have to perform gunshot detection on our dataset. In this notebook, we compare different model architectures and design for our models to see which architecture design and tweaks can perform best. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50e13d-520a-418e-8e3b-56e0f37a5fcf",
   "metadata": {},
   "source": [
    "## Environment Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034416a5-cb00-418c-b609-d6e443a364fb",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb39cce-eb5b-4efd-b694-7b1c101859c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Processing imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Import the functions we designed to be used accross notebooks to avoid redundancies and improve clarity\n",
    "from utils.common import list_files, create_dataframe, train_model, evaluate_model\n",
    "from utils.plotsPreprocessing import plot_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810abf5-d30c-4f7d-98eb-158cb929d7ba",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee98d3e4-a5cf-475c-886b-7152a0c99b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook in training mode\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the following in order to accommodate your environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mode = \"training\" if str(device) == \"cuda\" else \"development\" \n",
    "print(f\"Notebook in {mode} mode\")\n",
    "\n",
    "np.random.seed(4) # For reproducibility of results\n",
    "\n",
    "MODEL_DIR = \"models/preprocessing\"\n",
    "TRAIN_PREFIX = \"Data/Training data\"\n",
    "VAL_PREFIX   = \"Data/Validation data\"\n",
    "\n",
    "SAMPLE_RATE = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892b19b-1380-43de-b71e-bb622e7b1a49",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56354e0e-2b0c-4c6b-bf24-c764fe8fa79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 8 if str(device) == \"cuda\" else 2\n",
    "num_epochs = 20\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b373b-782c-4280-9090-80050eb299a9",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d863abc-ba18-4dc9-b1ac-6dcd56b0e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28790 training audios (597 gunshots, 28193 backgrounds) and 7190 validation audios (150 gunshots, 7040 backgrounds).\n"
     ]
    }
   ],
   "source": [
    "train_keys = list_files(TRAIN_PREFIX)\n",
    "val_keys   = list_files(VAL_PREFIX)\n",
    "\n",
    "# Using a df allows us to introduce labels in the AudioFileDataset\n",
    "train_df   = create_dataframe(train_keys)\n",
    "val_df     = create_dataframe(val_keys)\n",
    "\n",
    "# Creating a Sampler to account for the imbalance of the dataset\n",
    "train_counts = train_df[\"label\"].value_counts().to_dict()\n",
    "val_counts = val_df[\"label\"].value_counts().to_dict()\n",
    "weights = train_df[\"label\"].map(lambda x: 1.0 / train_counts[x])\n",
    "sampler = WeightedRandomSampler(weights.tolist(), num_samples=len(weights), replacement=True)\n",
    "\n",
    "print(f\"Found {len(train_keys)} training audios ({train_counts[1]} gunshots, {train_counts[0]} backgrounds) and {len(val_keys)} validation audios ({val_counts[1]} gunshots, {val_counts[0]} backgrounds).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90da47-0413-4c40-997f-8ab1ce76ee17",
   "metadata": {},
   "source": [
    "## Mel-Spectrogram preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8232e1c-20ef-44c4-a22b-1b6730d29c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(BaseSpectrogramDataset):\n",
    "    def process(self, waveform):\n",
    "        spectrogram = T.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=512, hop_length=128, n_mels=64)\n",
    "        return spectrogram(waveform)\n",
    "\n",
    "train_mel_spec = MelDataset(train_df, augmentation=1)\n",
    "val_mel_spec = MelDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8eabac3-7512-4708-8ad7-4e7e58deac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_mel_spec = DataLoader(\n",
    "    train_mel_spec,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "   \n",
    "val_loader_mel_spec = DataLoader(\n",
    "    val_mel_spec,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b41b97-a15c-4c3b-8346-e890c6ddf43f",
   "metadata": {},
   "source": [
    "## ResNet18 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd8ccd-bba3-4acb-b47d-bc409a0498f8",
   "metadata": {},
   "source": [
    "### Default Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b84c36-8c00-4b32-8a3f-59c0656100e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29dbaa84-8387-4100-a28b-aa03c02acd28",
   "metadata": {},
   "source": [
    "### Adjusting the Kernel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb1b4b-2315-4a51-bb91-ff96431263b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d34a0679-ee56-4229-9698-e44bd8a1e944",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba86a1-c1ea-4637-9848-b48d73bdf822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a28aec2-4b0f-4e3e-a876-75e2ec9723f9",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2efd9-1381-4b23-9c4f-59d14fe363a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfb81ef-166f-4457-af53-ce9197f79b63",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "X is best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0ecee-f3e9-4917-8571-cfea3c082573",
   "metadata": {},
   "source": [
    "#### Default Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48abe1-75cf-46d5-a0de-c053d447ae91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488be1ac-956f-4967-8d04-445cad713a39",
   "metadata": {},
   "source": [
    "### Default Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231287b-603d-406a-9db9-6a5e5197b725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d439022-8757-4b67-84a3-a12d3bb9e4c7",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4d579-53dc-4dc5-916b-8c36e3b9c928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9859b74-edae-4aa8-add6-8b7136e18154",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7c532-5f03-413a-8f4c-bbe440c9e8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfdae587-0818-49fc-a0e1-6f69d5846e3d",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c2db8-91ff-4f65-b610-6aca9493e5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e136df3a-97ba-4a74-8c48-32caec4b6d20",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "X is best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3af87-3107-41ce-a003-60fa472c7353",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228924a-51ac-4e1f-a9cf-7363d7c0edf4",
   "metadata": {},
   "source": [
    "### Default Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911535c7-b025-4b4c-bf2e-1ca1bb8c4626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d4390a1-c412-4bdf-aaff-085e4087630d",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350823d-43e1-4850-9cc0-f8abb0c0b1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0619a3-09f4-46e0-9923-7f79547c8ba1",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad66919-cb7e-443a-823c-f47f900bd0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc0eb281-a609-4828-8445-6deebbb14a6b",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da291c3-52a9-4ffe-8a3e-1f51325a0ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bdc6c2d-6f1f-4f83-b9a8-f065f2ab0518",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "X is best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75362767-a2d7-45cb-a09b-a109d75d6ea6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683237c4-3d9d-48e0-bb92-25eb5247b7a0",
   "metadata": {},
   "source": [
    "### Default Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b3fa8-708d-4c78-8257-f84c79345b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd3d718-4134-42ce-bf03-e525c1301113",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30bb33-f723-42c7-9333-bcf3d273b853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e6db92f-d669-40b8-bf77-fab7c25b24ce",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ddf43-e60d-492a-9113-e83bab55888b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e98839d-4140-47b3-85b5-01d9af3bbf89",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa254ca-7799-4b4f-8dd5-b2f8ae9c67b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeab2cf2-71a0-4637-b438-ba3c71eefbe0",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "X is best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697021cf-59c0-4fda-8eab-6387e49c96c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becccf12-79f1-45b2-b1a7-984d188bfee0",
   "metadata": {},
   "source": [
    "### Default Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e662986-c215-4429-a79e-a014a1bb3e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50389a95-64c8-4c11-a2d2-e0b7051ba08a",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbdd9d-7712-431b-b755-39f772dcf2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a22dd43-8693-49c7-a223-958dc5367e85",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e495182-1e6d-49a5-88bc-55232f5d6218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4770007f-5d6c-4675-8ed7-298c822e8f59",
   "metadata": {},
   "source": [
    "### Adjusting the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bbf5e-cbfb-4c94-a90c-68b7f5ddfafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "215fe67c-c7e6-40d6-96aa-8e0c13cbc6aa",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "X is best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56380802-1b2d-49de-b82f-339e18545db8",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd01ba3-33ac-427b-986a-f1eda4941c6d",
   "metadata": {},
   "source": [
    "*Table with all results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c778b-89b4-4fa4-8d83-a3c95cc30a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
