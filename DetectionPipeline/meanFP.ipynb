{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4d3639-3207-4f2a-9729-0fd6394f5ff0",
   "metadata": {},
   "source": [
    "# Determining the mean time between false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd447868-af72-41c5-aaff-5474c8cf7e6e",
   "metadata": {},
   "source": [
    "## Environment Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405627f-7480-4c20-9748-e5fdb01edb27",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc7ab6a-3ff4-4a87-a4fc-de24c84e0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torchvision.models import efficientnet_b3\n",
    "\n",
    "# Processing imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import the functions we designed to be used accross notebooks to avoid redundancies and improve clarity\n",
    "from utils.common import list_files, create_dataframe, train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910633ac-00ea-4160-9e74-c2971cd7f8c4",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d4c1c2-48b1-4c33-b253-5d6e5eaed726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook in training mode\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the following in order to accommodate your environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mode = \"training\" if str(device) == \"cuda\" else \"development\" \n",
    "print(f\"Notebook in {mode} mode\")\n",
    "\n",
    "MODEL_DIR = \"models/analysis\"\n",
    "TRAIN_PREFIX = \"/home/sagemaker-user/Data/Training data\" # Adapt this to your environment\n",
    "VAL_PREFIX   = \"/home/sagemaker-user/Data/Validation data\"\n",
    "\n",
    "SAMPLE_RATE = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7889f81-4d67-43d1-a572-2e71a0cad947",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a524bcf-efcc-41cc-b1b4-8ddff90df420",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 8 if str(device) == \"cuda\" else 2\n",
    "num_epochs = 30\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc289caa-7cca-472c-acc2-8537f1ba2352",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1144c3-9965-4a52-86bf-6de10f071ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28790 training audios (597 gunshots, 28193 backgrounds) and 7190 validation audios (150 gunshots, 7040 backgrounds).\n"
     ]
    }
   ],
   "source": [
    "train_keys = list_files(TRAIN_PREFIX)\n",
    "val_keys   = list_files(VAL_PREFIX)\n",
    "\n",
    "train_df   = create_dataframe(train_keys)\n",
    "val_df     = create_dataframe(val_keys)\n",
    "\n",
    "# Creating a Sampler to account for the imbalance of the dataset\n",
    "train_counts = train_df[\"label\"].value_counts().to_dict()\n",
    "val_counts = val_df[\"label\"].value_counts().to_dict()\n",
    "weights = train_df[\"label\"].map(lambda x: 1.0 / train_counts[x])\n",
    "sampler = WeightedRandomSampler(weights.tolist(), num_samples=len(weights), replacement=True)\n",
    "\n",
    "print(f\"Found {len(train_keys)} training audios ({train_counts[1]} gunshots, {train_counts[0]} backgrounds) and {len(val_keys)} validation audios ({val_counts[1]} gunshots, {val_counts[0]} backgrounds).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6509ec7-8acc-4f7c-9328-7d321f2de02c",
   "metadata": {},
   "source": [
    "## Building the training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38459a-54ac-4ef5-8452-65e2baf51d5d",
   "metadata": {},
   "source": [
    "We have to redefine our own dataset to be able to pass the file paths in order to compute the mean time between false paths using the fact that the first characters of the file path represent the UNIX timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add35e17-8f8d-47b7-8da8-a66a57de3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTimeFPDataset(Dataset):\n",
    "    def __init__(self, df, augmentation=None):\n",
    "        self.file_paths = df.index.values\n",
    "        self.labels = df[\"label\"].values\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform = self.load_audio(idx)\n",
    "        if self.augmentation is not None:\n",
    "            waveform = self.augment_wf(waveform, self.augmentation)\n",
    "        label = torch.tensor([self.labels[idx]])\n",
    "        spectrogram = self.process(waveform)\n",
    "        if self.augmentation is not None:\n",
    "            spectrogram = self.augment_spec(spectrogram, self.augmentation)\n",
    "        file_path = self.file_paths[idx] \n",
    "        return spectrogram, label, file_path\n",
    "\n",
    "\n",
    "    def load_audio(self, idx, normalize=True):\n",
    "        \"\"\"Loads and normalizes an audio file.\"\"\"\n",
    "        waveform, sample_rate = torchaudio.load(self.file_paths[idx])\n",
    "        if normalize:\n",
    "            waveform = (waveform - waveform.mean()) / waveform.std()\n",
    "        return waveform\n",
    "\n",
    "    def augment_wf(self, waveform, p):\n",
    "        if np.random.random() < p:\n",
    "            shift_amt = np.random.randint(-1, 1)\n",
    "            waveform = torch.roll(waveform, shifts=shift_amt, dims=-1)\n",
    "        if np.random.random() < p:\n",
    "            noise_scale = np.random.normal(0, 0.3)\n",
    "            noise = torch.randn_like(waveform) * noise_scale\n",
    "            waveform = waveform + noise\n",
    "        return waveform\n",
    "\n",
    "    def augment_spec(self, spectrogram, p):\n",
    "        if np.random.random() < p:\n",
    "            spectrogram = T.TimeMasking(time_mask_param=10)(spectrogram)\n",
    "        if np.random.random() < p:\n",
    "            spectrogram = T.FrequencyMasking(freq_mask_param=20)(spectrogram)\n",
    "        return spectrogram\n",
    "\n",
    "    def process(self, waveform):\n",
    "        spectrogram = T.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=256, hop_length=128, n_mels=64)\n",
    "        return spectrogram(waveform)\n",
    "\n",
    "train_delta = MeanTimeFPDataset(train_df)\n",
    "val_delta = MeanTimeFPDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78049a15-3116-44eb-9504-6d64084e1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_delta = DataLoader(\n",
    "    train_delta,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "   \n",
    "val_loader_delta = DataLoader(\n",
    "    val_delta,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0741a75c-7fbb-4a63-b478-83bb637510a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 57/57 [00:29<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background       1.00      1.00      1.00      7040\n",
      "     Gunshot       0.89      0.79      0.84       150\n",
      "\n",
      "    accuracy                           0.99      7190\n",
      "   macro avg       0.95      0.90      0.92      7190\n",
      "weighted avg       0.99      0.99      0.99      7190\n",
      "\n",
      "\n",
      "=== Performance Metrics ===\n",
      "Accuracy: 0.9937\n",
      "Precision: 0.8947\n",
      "Recall: 0.7933\n",
      "F1 Score: 0.8410\n",
      "\n",
      "=== Performance Metrics - Optimised Threshold ===\n",
      "Threshold: 0.0835\n",
      "Precision: 0.8421\n",
      "Recall: 0.8533\n",
      "F1 Score: 0.8477\n",
      "\n",
      "=== False Positive analysis ===\n",
      "Number of False Positives : 14\n",
      "Mean Time Between False Positives: 6874206 seconds (79 days, 13:30:05)\n",
      "Median Time Between False Positives: 11969 seconds (3:19:29)\n",
      "Maximum Time Between False Positives: 86542545 seconds (1001 days, 15:35:45)\n",
      "Minimum Time Between False Positives: 3 seconds (0:00:03)\n",
      "\n",
      "=== False Negative analysis ===\n",
      "Number of False Negatives : 31\n",
      "Mean Time Between False Negatives: 3983228 seconds (46 days, 2:27:08)\n",
      "Median Time Between False Negatives: 1811 seconds (0:30:11)\n",
      "Maximum Time Between False Negatives: 76423181 seconds (884 days, 12:39:41)\n",
      "Minimum Time Between False Negatives: 0 seconds (0:00:00)\n",
      "\n",
      "✅ Evaluation complete. Results saved in: evaluation/Run_20250316-1148\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"models/architecture/best_efficientnetb3.pth\", val_loader_delta, optimized_f1=True, delta_fp_fn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b185c4-5af6-427e-afca-d59fb7b68fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
